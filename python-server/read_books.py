from pathlib import Path
from typing import Dict, Any, Optional
from pydantic import BaseModel
import json
from openai import OpenAI
import fitz  # PyMuPDF
from termcolor import colored
from datetime import datetime
import shutil

# source for the infinite descent book: https://infinitedescent.xyz/dl/infdesc.pdf

# Configuration Constants

import os
from dotenv import load_dotenv
load_dotenv()

PDF_NAME = "Database_3.pdf"
BASE_DIR = Path("book_analysis")
PDF_DIR = BASE_DIR / "pdfs"
KNOWLEDGE_DIR = BASE_DIR / "knowledge_bases"
SUMMARIES_DIR = BASE_DIR / "summaries"
PDF_PATH = PDF_DIR / PDF_NAME
OUTPUT_PATH = KNOWLEDGE_DIR / f"{PDF_NAME.replace('.pdf', '_knowledge.json')}"
ANALYSIS_INTERVAL = 20  # Set to None to skip interval analyses, or a number (e.g., 10) to generate analysis every N pages
MODEL = "gpt-4o-mini"
ANALYSIS_MODEL = "o1-mini"
TEST_PAGES = 20  # Set to None to process entire book


class PageContent(BaseModel):
    has_content: bool
    knowledge: list[str]


def load_or_create_knowledge_base() -> Dict[str, Any]:
    if Path(OUTPUT_PATH).exists():
        with open(OUTPUT_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_knowledge_base(knowledge_base: list[str]):
    output_path = KNOWLEDGE_DIR / f"{PDF_NAME.replace('.pdf', '')}_knowledge.json"
    print(colored(f"ğŸ’¾ Saving knowledge base ({len(knowledge_base)} items)...", "blue"))
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({"knowledge": knowledge_base}, f, indent=2)

def process_page(client: OpenAI, page_text: str, current_knowledge: list[str], page_num: int) -> list[str]:
    print(colored(f"\nğŸ“– Processing page {page_num + 1}...", "yellow"))
    
    completion = client.beta.chat.completions.parse(
        model=MODEL,
        messages=[
            {"role": "system", "content": """
            ë‹¹ì‹ ì€ í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì œê³µëœ í˜ì´ì§€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¥´ì„¸ìš”:

            [ê±´ë„ˆë›¸ í˜ì´ì§€]
            - ëª©ì°¨
            - ì¥ ëª©ë¡
            - ì¸ë±ìŠ¤ í˜ì´ì§€
            - ê³µë°± í˜ì´ì§€
            - ì €ì‘ê¶Œ ì •ë³´
            - ì¶œíŒì‚¬ ì •ë³´
            - ì°¸ê³ ë¬¸í—Œ, ì„œì§€ì‚¬í•­
            - ê°ì‚¬ì˜ ê¸€

            [ì§€ì‹ì„ ì¶”ì¶œí•  í˜ì´ì§€]
            - ì„œë¬¸ ë‚´ìš© ì¤‘ í•µì‹¬ ê°œë…ì„ ì„¤ëª…í•˜ëŠ” ë¶€ë¶„
            - ë³¸ë¬¸ì˜ ì£¼ìš” í•™ìŠµ ë‚´ìš©
            - í•µì‹¬ ì •ì˜ì™€ ê°œë…
            - ì¤‘ìš”í•œ ì£¼ì¥ì´ë‚˜ ì´ë¡ 
            - ì˜ˆì‹œ ë° ì‚¬ë¡€ ì—°êµ¬
            - ì£¼ìš” ì—°êµ¬ ê²°ê³¼ë‚˜ ê²°ë¡ 
            - ë°©ë²•ë¡  ë˜ëŠ” ë¶„ì„ í”„ë ˆì„ì›Œí¬
            - ë¹„íŒì  í•´ì„ì´ë‚˜ ì¤‘ìš”í•œ ì¸ìš©ë¬¸

            [ì¶œë ¥ í˜•ì‹]
            - `has_content` : ìœ ì˜ë¯¸í•œ í•™ìŠµ ë‚´ìš©ì´ ìˆìœ¼ë©´ true, ì•„ë‹ˆë©´ false
            - `knowledge` : í•™ìŠµ ê°€ëŠ¥í•œ ì§€ì‹ í¬ì¸íŠ¸ë¥¼ ëª©ë¡ìœ¼ë¡œ ì¶”ì¶œ
            - êµ¬ì²´ì ì´ê³ , ì •í™•í•œ í‘œí˜„ ì‚¬ìš©
            - ì¤‘ìš”í•œ ìš©ì–´ëŠ” ì›ì–´ ê·¸ëŒ€ë¡œ ë³´ì¡´
            - í•„ìš” ì‹œ ê°„ë‹¨í•œ ì„¤ëª…ë„ ì¶”ê°€

            (ì£¼ì˜) í˜ì´ì§€ ì „ì²´ë¥¼ ìš”ì•½í•˜ì§€ ë§ê³ , í•™ìŠµ ê°€ì¹˜ê°€ ìˆëŠ” í¬ì¸íŠ¸ë§Œ ë½‘ì•„ë‚´ì„¸ìš”.
            """},
            {"role": "user", "content": f"Page text: {page_text}"}
        ],
        response_format=PageContent
    )
    
    result = completion.choices[0].message.parsed
    if result.has_content:
        print(colored(f"âœ… Found {len(result.knowledge)} new knowledge points", "green"))
    else:
        print(colored("â­ï¸  Skipping page (no relevant content)", "yellow"))
    
    updated_knowledge = current_knowledge + (result.knowledge if result.has_content else [])
    
    # Update single knowledge base file
    save_knowledge_base(updated_knowledge)
    
    return updated_knowledge

def load_existing_knowledge() -> list[str]:
    knowledge_file = KNOWLEDGE_DIR / f"{PDF_NAME.replace('.pdf', '')}_knowledge.json"
    if knowledge_file.exists():
        print(colored("ğŸ“š Loading existing knowledge base...", "cyan"))
        with open(knowledge_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            print(colored(f"âœ… Loaded {len(data['knowledge'])} existing knowledge points", "green"))
            return data['knowledge']
    print(colored("ğŸ†• Starting with fresh knowledge base", "cyan"))
    return []

def analyze_knowledge_base(client: OpenAI, knowledge_base: list[str]) -> str:
    if not knowledge_base:
        print(colored("\nâš ï¸  Skipping analysis: No knowledge points collected", "yellow"))
        return ""
        
    print(colored("\nğŸ¤” Generating final book analysis...", "cyan"))
    completion = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": """
            ì œê³µëœ í•™ìŠµ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, ê°„ê²°í•˜ì§€ë§Œ ìì„¸í•œ ìµœì¢… ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.  
            ê²°ê³¼ëŠ” **ë§ˆí¬ë‹¤ìš´(Markdown) í˜•ì‹**ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.

            [ìš”ì•½ ì‘ì„± ê·œì¹™]
            - ## ì œëª© í˜•ì‹ìœ¼ë¡œ ì£¼ìš” ì£¼ì œë¥¼ êµ¬ë¶„í•˜ì„¸ìš”
            - ### ì†Œì œëª©ì„ ì‚¬ìš©í•˜ì—¬ ì„¸ë¶€ ë‚´ìš©ì„ ì •ë¦¬í•˜ì„¸ìš”
            - ë¦¬ìŠ¤íŠ¸ëŠ” - ê¸°í˜¸ë¡œ ì •ë¦¬í•˜ì„¸ìš”
            - ì½”ë“œë‚˜ ê³µì‹ì€ `ì½”ë“œ ë¸”ë¡` ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”
            - ê°•ì¡°í•  ë‚´ìš©ì€ **êµµê²Œ** í‘œì‹œí•˜ì„¸ìš”
            - ìš©ì–´ ì„¤ëª…ì€ *ì´íƒ¤ë¦­ì²´*ë¡œ í‘œì‹œí•˜ì„¸ìš”
            - ì¤‘ìš”í•œ ë©”ëª¨ëŠ” > ì¸ìš©êµ¬ í˜•ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ì„¸ìš”

            [ì£¼ì˜ì‚¬í•­]
            - ê²°ê³¼ë¬¼ì—ëŠ” "ìš”ì•½ì…ë‹ˆë‹¤" ê°™ì€ ë¬¸êµ¬ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            - ë¶ˆí•„ìš”í•œ ë§ë¨¸ë¦¬ë‚˜ ê²°ë¡  ë¬¸êµ¬ ì—†ì´, ìš”ì•½ëœ ë‚´ìš©ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
            - ìµœëŒ€í•œ ìì—°ìŠ¤ëŸ½ê³  í•™ìŠµí•˜ê¸° ì¢‹ì€ í•œêµ­ì–´ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
            - ì œì¼ ë§ˆì§€ë§‰ ì¤„ì—ëŠ”, ìš”ì•½í•œ ë‚´ìš©ê³¼ ê´€ë ¨ì´ ìˆëŠ” ë„ì„œë“¤ì˜ ëª©ë¡ì„ ì¶”ì²œ í•´ ì£¼ì„¸ìš”.
            """},
            {"role": "user", "content": f"Analyze this content:\n" + "\n".join(knowledge_base)}
        ]
    )
    
    print(colored("âœ¨ Analysis generated successfully!", "green"))
    return completion.choices[0].message.content

def setup_directories():
    # Clear all previously generated files
    for directory in [KNOWLEDGE_DIR, SUMMARIES_DIR]:
        if directory.exists():
            for file in directory.glob("*"):
                file.unlink()  # Delete all files in these directories
    
    # Create all necessary directories
    for directory in [PDF_DIR, KNOWLEDGE_DIR, SUMMARIES_DIR]:
        directory.mkdir(parents=True, exist_ok=True)
    
    # Ensure PDF exists in correct location
    if not PDF_PATH.exists():
        source_pdf = Path(PDF_NAME)
        if source_pdf.exists():
            # Copy the PDF instead of moving it
            shutil.copy2(source_pdf, PDF_PATH)
            print(colored(f"ğŸ“„ Copied PDF to analysis directory: {PDF_PATH}", "green"))
        else:
            raise FileNotFoundError(f"PDF file {PDF_NAME} not found")

def save_summary(summary: str, is_final: bool = False):
    if not summary:
        print(colored("â­ï¸  Skipping summary save: No content to save", "yellow"))
        return
        
    # Create markdown file with proper naming
    if is_final:
        existing_summaries = list(SUMMARIES_DIR.glob(f"{PDF_NAME.replace('.pdf', '')}_final_*.md"))
        next_number = len(existing_summaries) + 1
        summary_path = SUMMARIES_DIR / f"{PDF_NAME.replace('.pdf', '')}_final_{next_number:03d}.md"
    else:
        existing_summaries = list(SUMMARIES_DIR.glob(f"{PDF_NAME.replace('.pdf', '')}_interval_*.md"))
        next_number = len(existing_summaries) + 1
        summary_path = SUMMARIES_DIR / f"{PDF_NAME.replace('.pdf', '')}_interval_{next_number:03d}.md"
    
    # Create markdown content with metadata
    markdown_content = f"""# Book Analysis: {PDF_NAME}
Generated on: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

{summary}

---
*Analysis generated using AI Book Analysis Tool*
"""
    
    print(colored(f"\nğŸ“ Saving {'final' if is_final else 'interval'} analysis to markdown...", "cyan"))
    with open(summary_path, 'w', encoding='utf-8') as f:  # Added encoding='utf-8'
        f.write(markdown_content)
    print(colored(f"âœ… Analysis saved to: {summary_path}", "green"))

def print_instructions():
    print(colored("""
ğŸ“š PDF ì±… ë¶„ì„ ë„êµ¬ ğŸ“š
---------------------------
1. ë¶„ì„í•  PDF íŒŒì¼ì„ ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ë„£ìœ¼ì„¸ìš”.
2. ì½”ë“œ ìƒë‹¨ì˜ PDF_NAME ê°’ì„ PDF íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”.
3. ì´ í”„ë¡œê·¸ë¨ì€ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
   - ì±…ì„ í˜ì´ì§€ ë‹¨ìœ„ë¡œ ë¶„ì„
   - ì£¼ìš” í•™ìŠµ í¬ì¸íŠ¸(ì§€ì‹) ì¶”ì¶œ ë° ì €ì¥
   - ì§€ì •ëœ ê°„ê²©ë§ˆë‹¤ ì¤‘ê°„ ìš”ì•½ ìƒì„± (ì„¤ì • ì‹œ)
   - ì „ì²´ ì±…ì— ëŒ€í•œ ìµœì¢… ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±

[ì„¤ì • ì˜µì…˜]
- ANALYSIS_INTERVAL: Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì¤‘ê°„ ìš”ì•½ì„ ìƒëµí•˜ê³ , ìˆ«ìë¡œ ì„¤ì •í•˜ë©´ Ní˜ì´ì§€ë§ˆë‹¤ ìš”ì•½ ìƒì„±
- TEST_PAGES: Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ì±…ì„ ì²˜ë¦¬í•˜ê³ , ìˆ«ìë¡œ ì„¤ì •í•˜ë©´ ì¼ë¶€ í˜ì´ì§€ë§Œ ë¶„ì„

ê³„ì†í•˜ë ¤ë©´ Enter í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”. ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.
""", "cyan"))

def main():
    try:
        print_instructions()
        input()
    except KeyboardInterrupt:
        print(colored("\nâŒ Process cancelled by user", "red"))
        return

    setup_directories()
    client = OpenAI()
    
    # Load or initialize knowledge base
    knowledge_base = load_existing_knowledge()
    
    pdf_document = fitz.open(PDF_PATH)
    pages_to_process = TEST_PAGES if TEST_PAGES is not None else pdf_document.page_count
    
    print(colored(f"\nğŸ“š Processing {pages_to_process} pages...", "cyan"))
    for page_num in range(min(pages_to_process, pdf_document.page_count)):
        page = pdf_document[page_num]
        page_text = page.get_text()
        
        knowledge_base = process_page(client, page_text, knowledge_base, page_num)
        
        # Generate interval analysis if ANALYSIS_INTERVAL is set
        if ANALYSIS_INTERVAL:
            is_interval = (page_num + 1) % ANALYSIS_INTERVAL == 0
            is_final_page = page_num + 1 == pages_to_process
            
            if is_interval and not is_final_page:
                print(colored(f"\nğŸ“Š Progress: {page_num + 1}/{pages_to_process} pages processed", "cyan"))
                interval_summary = analyze_knowledge_base(client, knowledge_base)
                save_summary(interval_summary, is_final=False)
        
        # Always generate final analysis on last page
        if page_num + 1 == pages_to_process:
            print(colored(f"\nğŸ“Š Final page ({page_num + 1}/{pages_to_process}) processed", "cyan"))
            final_summary = analyze_knowledge_base(client, knowledge_base)
            save_summary(final_summary, is_final=True)
    
    print(colored("\nâœ¨ Processing complete! âœ¨", "green", attrs=['bold']))

if __name__ == "__main__":
    main()
