from fastapi import FastAPI, Query
from pathlib import Path
from pydantic import BaseModel
from typing import Dict, Any
from openai import OpenAI
import fitz
import threading
import uuid
import time
import json
import os
from dotenv import load_dotenv
from termcolor import colored
from fastapi.middleware.cors import CORSMiddleware

load_dotenv()

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

UPLOAD_DIR = Path("../springboot-server/uploads/")
BASE_DIR = Path("book_analysis")
KNOWLEDGE_DIR = BASE_DIR / "knowledge_bases"
KNOWLEDGE_DIR.mkdir(parents=True, exist_ok=True)

progress_info = {}
task_results = {}

MODEL = "gpt-4o-mini"

class PageContent(BaseModel):
    has_content: bool
    knowledge: list[str]

def process_pdf(task_id: str, filename: str, start_page: int, end_page: int, recommend: bool, question: bool):
    pdf_path = UPLOAD_DIR / filename
    client = OpenAI()

    if not pdf_path.exists():
        print("íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    doc = fitz.open(str(pdf_path))
    total_pages = doc.page_count

    if start_page < 1 or end_page > total_pages or start_page > end_page:
        print("í˜ì´ì§€ ë²”ìœ„ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    pages_to_process = end_page - start_page + 1
    progress_info[task_id] = {"current_page": 0, "total_pages": pages_to_process, "done": False}
    knowledge_base = []

    for idx, page_num in enumerate(range(start_page - 1, end_page)):
        page = doc[page_num]
        page_text = page.get_text()

        print(colored(f"\nğŸ“– Processing page {page_num + 1}...", "yellow"))

        completion = client.beta.chat.completions.parse(
            model=MODEL,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ í•™ìŠµ ê°€ëŠ¥í•œ ì§€ì‹ì„ ì¶”ì¶œí•˜ì„¸ìš”."},
                {"role": "user", "content": f"Page text: {page_text}"}
            ],
            response_format=PageContent
        )

        result = completion.choices[0].message.parsed
        if result.has_content:
            knowledge_base.extend(result.knowledge)

        progress_info[task_id]["current_page"] = idx + 1
        time.sleep(1)

    summary_prompt = [
        {"role": "system", "content": """
            ë‹¤ìŒ í•™ìŠµ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì•„ë˜ í˜•ì‹ì— ë§ê²Œ JSONìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”:
            knowledgeí•­ëª©ì€ jsonì„ ê¸°ë°˜ìœ¼ë¡œ **ë§ˆí¬ë‹¤ìš´(Markdown) í˜•ì‹**ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.

            [ìš”ì•½ ì‘ì„± ê·œì¹™]
            - ## ì œëª© í˜•ì‹ìœ¼ë¡œ ì£¼ìš” ì£¼ì œë¥¼ êµ¬ë¶„í•˜ì„¸ìš”
            - ### ì†Œì œëª©ì„ ì‚¬ìš©í•˜ì—¬ ì„¸ë¶€ ë‚´ìš©ì„ ì •ë¦¬í•˜ì„¸ìš”
            - ë¦¬ìŠ¤íŠ¸ëŠ” - ê¸°í˜¸ë¡œ ì •ë¦¬í•˜ì„¸ìš”
            - ì½”ë“œë‚˜ ê³µì‹ì€ `ì½”ë“œ ë¸”ë¡` ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”
            - ê°•ì¡°í•  ë‚´ìš©ì€ **êµµê²Œ** í‘œì‹œí•˜ì„¸ìš”
            - ìš©ì–´ ì„¤ëª…ì€ *ì´íƒ¤ë¦­ì²´*ë¡œ í‘œì‹œí•˜ì„¸ìš”
            - ì¤‘ìš”í•œ ë©”ëª¨ëŠ” > ì¸ìš©êµ¬ í˜•ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ì„¸ìš”
            

            {{
                "knowledge": [...],
                "recommendation": {"ì œëª©": "ë§í¬", ...},
                "questions": {{"1": {{"ë¬¸ì œ": "...", "ì •ë‹µ": "..."}}, ...}}
            }}
            'recommendation'ê³¼ 'questions'ëŠ” ì‚¬ìš©ìê°€ ìš”ì²­í•œ ê²½ìš°ì—ë§Œ í¬í•¨í•˜ì„¸ìš”.
            recommendationì—ëŠ” ê´€ë ¨ ë„ì„œ, ìë£Œ ë“±ì„ ë„£ê³ , ë§í¬ì—ëŠ” ì‹¤ì œ ì‘ë™í•˜ëŠ” ë§í¬ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
            JSON ì´ì™¸ì˜ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.
        """},
        {"role": "user", "content": json.dumps({
            "knowledge": knowledge_base,
            "include_recommendation": recommend,
            "include_questions": question
        })}
    ]

    try:
        ai_response = client.chat.completions.create(
            model=MODEL,
            messages=summary_prompt
        )
        combined_json = json.loads(ai_response.choices[0].message.content)
    except Exception as e:
        print("ìš”ì•½ íŒŒì‹± ì‹¤íŒ¨:", e)
        combined_json = {
            "knowledge": knowledge_base,
            "recommendation": {"ì˜¤ë¥˜": "ì¶”ì²œ ìë£Œ íŒŒì‹± ì‹¤íŒ¨"} if recommend else {},
            "questions": {"ì˜¤ë¥˜": "ë¬¸ì œ ìƒì„± ì‹¤íŒ¨"} if question else {}
        }

    task_results[task_id] = combined_json
    progress_info[task_id]["done"] = True
    print(colored(f"âœ… Finished processing {pages_to_process} pages!", "green"))

@app.get("/process")
def start_processing(
    filename: str,
    start_page: int = 1,
    end_page: int = 1,
    recommend: bool = Query(False),
    question: bool = Query(False)
):
    task_id = str(uuid.uuid4())
    thread = threading.Thread(target=process_pdf, args=(task_id, filename, start_page, end_page, recommend, question))
    thread.start()
    return {"message": "Processing started", "task_id": task_id}

@app.get("/progress")
def get_progress(task_id: str):
    if task_id not in progress_info:
        return {"error": "Task not found"}
    return progress_info[task_id]

@app.get("/result")
def get_result(task_id: str):
    if task_id not in task_results:
        return {"error": "Task not completed or not found"}
    return task_results[task_id]
